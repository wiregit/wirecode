<?xml version="1.0"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc private="Gnutella Developer Forum"?>
<?rfc header="The GDF"?>
<?rfc compact="yes"?>
<?rfc toc="yes"?>
<rfc docname="gnutella-unicast-search-01">
  <front>
    <title abbrev="GUESS">
	  Gnutella UltraPeer Extension for Scalable Searches (GUESS) v0.01
	</title>
    <author initials="S.D" surname="Daswani" fullname="Susheel Daswani">
	  <organization>LimeWire LLC</organization>
	  <address>
	    <email>sdaswani@limewire.com</email>
	    <uri>http://www.limewire.org</uri>
      </address>
	</author>
    <author initials="A.F" surname="Fisk" fullname="Adam A. Fisk">
	  <organization>LimeWire LLC</organization>
	  <address>
	    <email>afisk@limewire.com</email>
	    <uri>http://www.limewire.org</uri>
      </address>
	</author>
    <date month="August" year="2002"/>
    <area>applications</area>
	<keyword>Gnutella</keyword>
	<keyword>UDP</keyword>	
	<keyword>unicast</keyword>	
	<keyword>search</keyword>	
	<keyword>GDF</keyword>	
	<keyword>walk</keyword>	
	<keyword>crawl</keyword>	
	<keyword>Gnutella Developer Forum</keyword>	
	<keyword>LimeWire</keyword>	
    <abstract>
	  <t>
	    "GUESS" is a technique for performing iterative unicast 
		searches of UltraPeers on the Gnutella network, or "UltraPeer 
		crawling."  Shifting from the current broadcast search model 
		to this system can dramatically reduce the 
		overall network bandwidth, CPU, and memory required to support 
		the Gnutella search architecture while providing comparable 
		search results to the old broadcast model.  For rare files, the 
		unicast search model may even provide better results than 
		broadcast.
	  </t>
    </abstract>
  </front>

  <middle>
    <section anchor="intro" title="Introduction">
	  <section title="Purpose">
	  <t>
        The use of broadcast searches with high Time To Live (TTL)s on the 
	    Gnutella network uses a great deal of bandwidth and provides little 
	    control over the propagation of 
		messages.<xref target="refs.RandomWalk"/>  This document seeks to 
	    alleviate both problems through the use of iterative unicast 
	    searches of Gnutella UltraPeers.<xref target="refs.UltraPeer"/>
	    In this scheme, a client continuously queries UltraPeers with a TTL 
	    of 1 until the desired number of search results is achieved.  Due 
	    to the number of nodes that may be dynamically queried in this model,
	    these messages are sent over UDP in the absence of static TCP 
	    connections.  This proposal is not intended to replace work 
		done in areas such as query 
		meshes.  (See <xref target="refs.QueryMesh"/> and <xref target="refs.http_mesh_proxy"/>)
		It does not, for example, easily allow existing web servers to 
		be modified to service queries.  Rather, it combines aspects of 
		several powerful ideas from different parties, most notably the 
		importance of carefully controlling query propagation and the 
		potential for queries and replies to be sent over UDP, making 
		such a system feasible.
	  </t>
	  </section>
	  <section anchor="requirements" title="Requirements">
        <t>The key words “MUST”, “MUST NOT”, “REQUIRED”, 
		“SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, 
		“RECOMMENDED”, “MAY”, and “OPTIONAL” in this 
		document are to be interpreted as described in 
		RFC 2119.<xref target="RFC2119"/>
		An implementation is not compliant if it fails to satisfy one or 
		more of the MUST or REQUIRED level requirements for the protocols 
		it implements. An implementation that satisfies all the MUST or 
		REQUIRED level and all the SHOULD level requirements for its 
		protocols is said to be “unconditionally compliant”; one that 
		satisfies all the MUST level requirements but not all the SHOULD 
		level requirements for its protocols is said to be “conditionally
        compliant.”</t>
	  </section>
	  <section anchor="problems" title="Problems with the Current Model">
	    <t>The current broadcast search model consumes excessive bandwidth 
	    and produces a high load on nodes.  This occurs because: 

	      <list style="bullets">
	        <t>The number of nodes queried per search is uncontrolled.</t>
	        <t>Even if the number of nodes queried per search were constant,
		    the number of query hits generated per search would still be 
		    highly variable.</t>
	      </list>
        </t>
		  
        <section anchor="queries" title="Out of Control Queries">
	      <t>The first problem is a result of the volatile, ad-hoc nature of
		  Gnutella.  Nodes come and go unpredictably, making the connectivity
		  of different parts of the network highly variable, or at least
		  potentially so.  The current query model accounts for this
		  volatility by flooding -- it always takes whatever it can.
		  It does this by:

	        <list style="bullets">
		      <t>Sending queries with high TTLs (typically 7), making the 
		      number of nodes searched unpredictable and dependent upon the 
		      network topology.</t>
		      <t>Always forwarding queries to all connected nodes (it floods 
		      whenever the TTL is above 1) regardless of variable conditions.</t>
	        </list>

	      As a result, searches for common keywords in highly 
		  connected areas of the network have disproportionate impacts 
		  on network load, while searches for less common keywords in
		  less connected areas are not able to reach enough nodes to
		  obtain a satisfactory number of replies.
		  </t> 
		</section>

		<section anchor="hits" title="Out of Control Query Hits">
		  <t>While the unpredictable nature of queries presents the first half 
		  of the problem, the unpredictable nature of query hits has a comparable 
		  debilitating effect.  The problem with queries spills over into 
		  hits -- a variable number of nodes queried results 
		  in a variable number of query hits.  The problem is more serious 
		  than this, however.  The number of query hits generated per 
		  search also varies independently because:
	  
	        <list style="bullets">
	          <t>Some searches match a far higher percentage of files than other
		      searches (a search for "txt" produces more results than a search
		      for "The_Gettysburg_Address.txt").</t>
	          <t>Some nodes share more files than others, so the query hits 
		      depend not only on the number of nodes queried, but on which
		      nodes queries happen to reach.</t>
	        </list>

		  With this system, users frequently get more results than they need 
		  for popular content while they have a difficult time finding files
		  that are not as widely distributed.  In either case, queries and query 
		  hits follow the same model where they are allowed to run wild,
		  devouring network resources as they go.
	      </t>
	    </section>
	  </section>
	  <section title="Switch to Iterative Unicast, or 'UltraPeer Crawling'">
	    <t>
	      We propose to alleviate these issues by reducing the TTL to 1 on
		  outgoing queries and by sending queries to one UltraPeer at a time
		  until some desired number of results is received or a limit on
		  the number of UltraPeers queried is reached.  Such a change 
		  grants the client initiating a query substantially more control
		  over the number of nodes the query reaches and over the number of 
		  query hits generated.  As such, it takes a significant step
		  towards solving the primary two problems with the current query
		  model noted above.  It does not eliminate these issues because
		  UltraPeers have varying numbers of leaves, nodes still share
		  varying numbers of files, and some searches will still return
		  far more results from given UltraPeers than others.
		  Nevertheless, this change dramatically mitigates the effects
		  of these problems.
	    </t>
	  </section>
	</section>
	<section anchor="searching_architecture" title="Searching Architecture">
	  <t>
	    In several ways, this scheme is simple and easy to 
		implement.  In particular, the system is completely transparent
		to leaves.  From the leaf perspective, the search system has
		not changed at all.  This simplifies the design and allows 
		any leaves not implementing this proposal to benefit from it
		nevertheless.  From the UltraPeer perspective, implementing this
		proposal means on a high level simply means sending out all 
		queries with TTL=1 while querying a much larger set of UltraPeers 
		directly over UDP.

		<vspace/>
		<vspace/>
		The details of the UltraPeer changes are significant.  UltraPeers 
		must send queries iteratively to known UltraPeers via UDP,
		stopping when enough results are received.  UltraPeers are 
		also responsible for maintaining a full cache of other 
		UltraPeers that they can query via UDP.  On the server side,
		UltraPeers must listen on a UDP port, and they must send their
		responses over the same UDP port they are listening on.  Aside from
		the protocol used when sending or receiving messages, however,
		the changes are minimal.
		The following sections discuss these changes.  In this discussion,
		the "client" is the UltraPeer initiating the query, either on its
		own behalf or on behalf of one of its leaves (most importantly,
		the "client" is never a leaf -- it is always the UltraPeer).  
		The "server" is the receiver of the query, which can either
		be an UltraPeer or a leaf.
	  </t> 
	  <section anchor="algorithm" title="Client">
	    <t>
		UltraPeers query other UltraPeers one by one until either:
		  <list style="numbers">
		    <t>
			  The desired number of results is received.
			</t>
			<t>
			  The maximum number of UltraPeers is queried.
			</t>
		  </list>
		
		The client MUST pause for a reasonable amount
		of time between UltraPeer queries, perhaps about
		200 milliseconds.  This pause accounts for network latency, as it
		takes a variable amount of time to receive results from an UltraPeer
		and its leaves.  This interval gives the previous query time to supply
		all of its results, potentially reaching the desired number
		and ending the query.  The optimal interval between searches
		should be determined by experimentation, but implementors MUST
		send as few queries as possible without degrading user experience. 
		Implementations may also vary the interval between queries 
		depending on how many UltraPeers have already been reached.
		For example, the interval may be 400 milliseconds for the 
		first 10 UltraPeers, but then go down to 200 for the next 100.

		<vspace/>
		<vspace/>
		With regard to 1) above, implementors have some flexibility, 
		particularly in their technique for
		determing what they consider "enough" results.  
		A simple algorithm would be for the client to continue 
		querying until it has received 100 results or queried 1,000 UltraPeers, 
		for example.  An alternative would be for the number of results 
		considered "enough" to decrease as a function
		of the number of UltraPeers searched.  This algorithm would 
		recognize, for example, that if a search has returned no
		results after querying 500 UlraPeers, it is unlikely
		to get very many results from querying the next 500,
		and it may be satisfied as soon as it receives any results
		at all and stop there.  This would reduce the total number
		of UltraPeers required to service queries for rare files.
		The details of these algorithms should also be determined 
		through experimentation by client developers, again keeping
		in mind that the overall goal is to reduce query and query 
		hit traffic for everyone while maintaining searchability and 
		improving searchability for rare files.  Clients should also 
		keep in mind that an overly aggressive implementation will
		ultimately damage their own clients.
		
		<vspace/>
		<vspace/>
		When performing this search, there are several rules that
		UltraPeers MUST follow.  These are:
		  <list style="numbers">
		    <t>
			  Searches MUST NOT be sent to more than 10,000
			  UltraPeers.
			</t>
			<t>
			  Clients MUST NOT seek more than 1,000 results.
			</t>
			<t>
			  Clients MUST NOT query more than 1 UltraPeer every
			  50 milliseconds.
			</t>
		    <t>
			  UltraPeers MUST NOT query the same UltraPeer more 
			  than once.
			</t>
			<t>
			  Although already implied by 4), for clarity, a node
			  MUST NOT send a second query to an UltraPeer if it
			  does not receive responses to the first query (it
			  MUST NOT consider that the datagram was lost and
			  requery as a result).
			</t>
		  </list>

	    These numbers SHOULD be considered the absolute maximum
		values, and they are not the settings developers should use.
		Again, the optimal limits should be determined by 
		experimentation, but the above rules always apply.  Implementors
		should keep in mind that Gnutella is a network that relies on
		the fact that other clients are not overly selfish or
		abusive -- Gnutella relies on trust to a large degree.  
		The overall goal of this change is to reduce 
		query and query hit traffic for 
		everyone while maintaining current levels of searchability 
		and even improving
		searchability for rare files.  The reduction in traffic
		should reduce the bandwidth, CPU, and memory load on
		UltraPeers, but this is only possible if developers use 
		conservative values when writing their implementations.
		</t>
	  </section>
	  <section anchor="server" title="Server">
	    <t>
	    The changes on the server side are less significant.  Again,
		no changes are required for leaves.  In fact, leaves SHOULD NOT open
		UDP ports for incoming traffic, as they never receive UDP
		messages directly.
		UltraPeers MUST, however, open a port
		for incoming UDP traffic, and they MUST use the same 
		port that they are using for incoming Gnutella messages 
		over TCP.  When a server receives a message over its open UDP
		port, it MUST send any replies via UDP and over the same
		port it is listening on.  As in the current Gnutella 
		network, all replies are sent back to the sender.  This is
		an important point in terms 
		of <xref target="security">security</xref>.  Otherwise,
		servers should respond to messages just as if they 
		recieved them over TCP.  Servers SHOULD accept all of the
		traditional Gnutella messages, as defined in 
		the <xref target="refs.clip2">Gnutella RFC</xref>.
		
		<vspace/>
		<vspace/>
		On the server side, UltraPeers also MUST start forwarding 
		TTL=1 queries to leaves.  Without this change, queries would
		have to be sent with TTL=2, which would lessen the fine-grained
		control over the query and would eliminate benefits such as
		no longer needing to concern ourselves 
		with <xref target="cycles">cycles</xref>.  The current practice
		of not forwarding TTL=1 queries to leaves also fails to take
		advantage of the powerful UltraPeer infrastructure that 
		can be used more productively. 
		</t>
	  </section>
	  <section anchor="latency" title="Latency">
	    <t>
		  This change impacts the latency of search results.  If a
		  given search is sent to 10,000 UltraPeers with an interval
		  between individual UltraPeer queries of 100, the complete search 
		  will take 1,000 seconds, or over 15 minutes.  This may be
		  impractical.  Due to these limitations, developers MAY choose
		  to decrease the interval between searches as more UltraPeers
		  are searched.
		</t>
	  </section>
	</section>
	<section anchor="discovery" title="UltraPeer Discovery">
	    <t>
		  For this scheme to work, all UltraPeers must have the
		  ability to discover other UltraPeers that accept incoming
		  messages over UDP.  In fact, UltraPeer discovery may be one
		  of the most challenging components of this proposal, as
		  UltraPeers do not simply have to discover other UltraPeers -- 
		  they have to discover LOTS of them.  As we will see, the 
		  scheme has UltraPeer discovery built in to some degree. 
		  UltraPeers supporting this proposal MUST advertise this fact
		  using a <xref target="ggep_pongs">GGEP extension</xref> in
		  pongs.  there are three techniques for discovering these
		  marked pongs on the network:
		    <list style="numbers">
			  <t>
			    Through standard Gnutella broadcast pings and pong caching.
			  </t>			    
			  <t>
                Through specialized pings sent over UDP.
			  </t>
			  <t>
			    Through the storing of the IP and port of the many queries
				and pings passing through UltraPeers over UDP.
			  </t>
			</list>

		  The last technique is perhaps the most intriguing.  Each UltraPeer
		  crawl may send out queries to 10,000 other nodes.  As a result,
		  UltraPeers will naturally receive large numbers of queries over UDP
		  from other UltraPeers that must be supporting this proposal.  They
		  can simply treat these queries as pongs, and add those UltraPeers 
		  to their cache.  This is made possible because the host sending the
		  query has to be listening on the same port stored in the
		  datagram.  The same is true for any pings received over UDP.  
		  While these incoming messages will only supply the IP address and 
		  port of hosts supporting GUESS without the additional data 
		  contained in normal pongs, the IP address and port are really all 
		  that are necessary for our purposes.  This built-in distribution 
		  of host information can dramatically reduce the need for 
		  any pings and pongs at all -- so much so that UltraPeers 
		  MUST store the IP and port from all UDP queries they receive.
		  
		  <vspace/>
		  <vspace/>
		  The other specialized technique for UltraPeer discoverty is the
		  use of the normal Gnutella ping, only over UDP.  When UltraPeers
		  receive pings over UDP, they should take special action.  Instead 
		  of returning the normal pongs, UltraPeers are REQUIRED to send 
		  pongs from other UltraPeers with 
		  the <xref target="ggep_pongs">GGEP extension</xref> marking 
		  support for GUESS.  They SHOULD send some moderate number of these
		  UltraPeer pongs, somewhere in the range of about 5-20.  Given
		  that GUESS UltraPeer discovery is one of the more difficult 
		  aspects of the proposal, the optimal number of pongs to send 
		  should be determined by experimentation.  UltraPeers MUST NOT
		  include a pong for themselves in the returned set, as the
		  pinging UltraPeer already knows about the UltraPeers it pings.
		  This technique allows nodes to discover UltraPeers outside the
		  network horizon of normal broadcast pings.

		  <vspace/>
		  <vspace/>
		  Using these techniques, UltraPeers also MUST maintain
		  a full cache of other UltraPeers to query.  
		  Because leaves always query the network via their
		  UltraPeer, leaves do not have to maintain any of this 
		  information -- this is the UltraPeer's 
		  responsibility.		  
		  <vspace/>
		  <vspace/>
		  If an UltraPeer's cache of other GUESS-supporting UltraPeers 
		  drops below a certain threshold, for example 5,000, the
		  UltraPeer MUST use these techniques to refresh its 
		  UltraPeer cache.
		  
		  <vspace/>
		  <vspace/>
		  While UltraPeers MUST maintain an adequate cache of 
		  other UltraPeers to query, they also MUST send a minimum
		  number of pings to make this possible, less the network
		  become flooded with ping and pong traffic.
		</t>
	</section>


      <section anchor="udp" title="UDP">
	    <t>
	      In this scheme, clients must dynamically query a 
	      potentially high number of UltraPeers directly for each 
		  search.  In the current Gnutella network, all messages are
		  sent using TCP, so the most obvious implementation of this
		  proposal would use a new, transient connection also over TCP.  
		  Opening and closing TCP connections incurs significant CPU 
		  and memory costs, however, potentially making the proposed
		  change unworkable.  Moreover, Windows 95/98/Me limit TCP
		  connections to 100.  While this setting can be changed in the
		  registry, these systems were clearly not designed to handle 
		  this number of simultaneous connections.  TCP also uses 
		  significantly more bandwidth and increases delay. 
		  As others have noted, however, the 
		  reliability of TCP is not a requirement for Gnutella queries
		  and hits.<xref target="refs.agthorr"/>  If a 
		  message is lost, who cares?  
		  In fact, these queries and their associated replies can 
		  easily be sent over UDP.  In many ways, UDP is the more 
		  appropriate transport layer protocol -- we're sending messages 
		  to an amorphous group of nodes, and reliability is not 
		  a requirement.  Clients wishing to implement this change
		  MUST do so over UDP, as a TCP implementation would incur
		  excessive overhead for other nodes, and would be 
		  impossible without a new, transient connection.
	    </t>
		<section anchor="port" title="Open a UDP Port">
		  <t>
		    To implement this change, UltraPeers MUST open a UDP
			port that listens for incoming UDP traffic.  It is
			RECOMMENDED that UltraPeers listen on port 6346, the 
			same port registered for Gnutella for TCP.
			UltraPeers MAY, however, listen 
			on a different port, particularly when, for example,
			there is another Gnutella client listening on 6346,
			or when another application is using that port for
			any reason.  In all cases, clients MUST
			listen on the same port for both TCP and UDP traffic.
			This makes the implementation slightly more
			rigid.  The IP and TCP port are already reported in a
			number of Gnutella messages, headers, and extensions, 
			however, and this choice makes the reuse of that 
			information possible.  One example is the "Listen IP" 
			connection handshaking header that we will use right
			away to check the firewalled status of leaves.
		  </t>
		</section>
		<section anchor="fragmentation" title="Fragmentation">
		  <t>
		    One difference between UDP and TCP is that UDP does 
			not perform any segmenting of datagrams on its own:
			it sends a single datagram that may be split into
			multiple packets at the IP layer, either at the 
			originating host or at an intermediate router.  
			This fragmentation depends upon the 
			Maximum Transmission Unit (MTU) of the underlying
			link-layer.<xref target="refs.TCPIP"/>  
			<vspace/>
			<vspace/>
			Fragmentation of datagrams in itself is far from
			disastrous.  The IP layer reassembles packets into 
			complete datagrams at the destination host, making
			the process largely transparent to application 
			developers.  The danger lies, however, in the 
			possibility that individual packets are lost.  If 
			any fragment is lost, the entire datagram 
			is lost.<xref target="refs.TCPIP"/>  It is
			therefore RECOMMENDED that clients take steps
			to minimize the size of their datagrams to avoid
			excessive fragmentation.  The MTU of modem links
			can be prohibitively small, as low as 296 bytes,
			so we make no attempt to remain below this 
			threshold.<xref target="RFC1191"/>  These links
			should only occur on the edges of the network,
			however, as long as UltraPeer election algorithms are 
			correctly measuring bandwidth.  This means that any
			fragmentation that may occur along modem links will
			likely result in little to no packet loss, so we
			need not consider this barrier when determing
			datagram sizes.  In general, clients SHOULD limit the
			size of their datagrams whenever appropriate.  A limit
			of 512 is very conservative, and limiting datagrams 
			to 1,500 bytes or less should avoid fragmentation on
			the vast majority of 
			routers.<xref target="RFC1191"/>  This is because 
			1,500 bytes is the MTU for Ethernet links, which most
			TCP/IP stacks take into account.
			
			<vspace/>
			<vspace/>	
			This will often not be possible for query hits.  
			To address this problem, it is RECOMMENDED that 
			developers break up large query hits into multiple smaller 
			query hits.  This will increase the bandwidth required 
			to return results only slightly (due to sending the same 
			header multiple times) while reducing or eliminating fragmentation.
			It also avoids the current "all or nothing" approach where all 
			results from a host are lost if one packet is lost.  In this 
			scheme, some hits can still get through when a packet 
			from another hit is lost.
		  </t>
		</section>
		<section anchor="congestion" title="Congestion">
		  <t>
		    Another significant difference between TCP and UDP
			is that UDP does not provide congestion control.
			Given that this query scheme dramatically reduces
			overall message traffic, congestion may not be a 
			concern.  Particularly because clients will no longer receive
			the floods of query hits currently associated with 
			queries for popular content (probably the most severe 
			case of congestion on the current network), packet loss
			rates under this scheme should be significantly lower. 
			If congestion does prove to cause a 
			high degree of packet loss, however, clients
			may be forced to implement congestion control
			at the application layer.  The architecture for
			such a scheme is beyond the scope of this
			proposal.
		  </t>
		</section>
	  </section>

	    <section anchor="security" title="Security Considerations">
		  <section title="Distributed Denial of Service (DDOS) Attack">
		  <t>
			In the past, a principal objection to using UDP has been
			that it allows anyone to easily execute a DDOS attack
			on any target machine.  This concern has been based on the
			assumption that queries would require an extension listing
			the IP address and UDP port to reply to, however.  In this
			proposal, this extension is not required, as responses are
			always sent directly back to the node that sent them, 
			rendering such an attack impossible.
	      </t>
		  </section>
		</section>
      <section anchor="ggep" title="GGEP Extensions">
	    <section anchor="ggep_pongs" title="Advertise UDP port in Pongs">
	      <t>
		    UltraPeers that are capable of receiving Gnutella 
			messages over UDP MUST advertise that fact in a
			new GGEP extension in 
			pongs.<xref target="refs.GGEP"/>
            The GGEP extension should have the value "UDP" as its
			extension header.  The extension value should be the version
			number of the protocol supported - for example, this is
			version .01.  The version number in the GGEP block should the
			version number support multiplied by 10 (i.e. .01 would have 1,
			2.4 would have 24, etc.).  This will allow for potential
			feature specific use in the future.
		  </t>
		</section>
	  </section>
    <section anchor="features" title="Additional Features">
	  <section anchor="cycles" title="Cycles No Longer a Concern">
	    <t>
	      Adoption of this proposal has several additional benefits.  For 
		  example, concern for cycles in intra-UltraPeer connections is 
		  eliminated.  In the current network, cycles can be a serious 
		  problem in the worst case, resulting in nodes receiving many 
		  duplicate messages, wasting bandwidth, CPU, and 
		  memory.<xref target="refs.RandomWalk"/>  This eliminates
		  these duplicates except in the case where leaves are connected to 
		  multiple UltraPeers, and two or more of their UltraPeers are sent
		  the same query.  
	    </t>
	  </section>
	  <section anchor="push" title="Higher Success Rate for Push Downloads">
	    <t>
		  This query scheme gracefully handles push downloads.  In
		  fact, it incorporates many of the ideas of the 
		  Push Proxy proposal.<xref target="refs.push_proxy"/>
		  This scheme does not, however, allow two firewalled hosts
		  to download from each other, as in the "Download Proxy"
		  proposal.<xref target="refs.download_proxy"/>  In the current
		  network, push requests frequently fail, primarily because
		  the node serving the file may be 7 hops away from the node
		  requesting a file, and the request has to travel through
		  all intervening nodes.  As a result, if any node along that
		  path leaves the network, the push will not go through.
		  With the adoption of this proposal, success rates for 
		  push request should increase dramatically, as the node 
		  serving the file will only be from 2 to 3 hops away 
		  (depending on whether the node serving the file is
		  a leaf or an UltraPeer).
		</t>
	  </section>
	  <section anchor="stop" title="Stopping Queries Has Meaning">
	    <t>
		  Another benefit of this scheme is that the user manually "stopping"
		  a query can, in fact, stop that query from being sent to more
		  hosts, saving network resources.
		</t>
	  </section>
	</section>
  </middle>
  <back>
    <references>
	  <reference target="http://www.cs.princeton.edu/~qlv/download/searchp2p_full.pdf" 
	             anchor="refs.RandomWalk">
	    <front>
		  <title>
		    Search and Replication in Unstructured Peer-to-Peer Networks
		  </title>
		  <author initials="Q.V." surname="Lv" fullname="Qin Lv">
		    <organization>
			  Department of Computer Science, Princeton University
			</organization>
			<address>
			  <email>
			    qlv@cs.princeton.edu
			  </email>
			</address>
		  </author>

		  <author initials="P.C." surname="Cao" fullname="Pei Cao">
		    <organization>
			  Cisco Systems, Inc. 
			</organization>
			<address>
			  <email>
			    cao@cisco.com
			  </email>
			</address>
		  </author>

		  <author initials="E.C." surname="Cohen" fullname="Edith Cohen">
		    <organization>
			  AT&T Labs-Research
			</organization>
			<address>
			  <email>
			    edith@research.att.com
			  </email>
			</address>
		  </author>

		  <author initials="K.L." surname="Li" fullname="Kai Li">
		    <organization>
			  Department of Computer Science, Princeton University
			</organization>
			<address>
			  <email>
			    li@cs.princeton.edu
			  </email>
			</address>
		  </author>

		  <author initials="S.S." surname="Shenker" fullname="Scott Shenker">
		    <organization>
			  International Computer Science Institute (ICSI) 
			</organization>
			<address>
			  <email>
			    shenker@icsi.berkeley.edu
			  </email>
			</address>
		  </author>

		  <date month="June" year="2002"/>
		</front>
	  </reference>
	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/Ultrapeer/Ultrapeers_proper_format.html" 
	             anchor="refs.UltraPeer">
		<front>
	      <title>UltraPeers: Another Step Towards Gnutella Scalability</title>
		  <author initials="C.R." surname="Rohrs" fullname="Christopher Rohrs">
		    <organization>LimeWire LLC</organization>
			<address>
			  <uri>http://www.limewire.org</uri>
			</address>
		  </author>
		  <author initials="A.S." surname="Singla" fullname="Anurag Singla">
		    <organization>LimeWire LLC</organization>
			<address>
			  <uri>http://www.limewire.org</uri>
			</address>
		  </author>
		  <date month="December" year="2001"/>
		</front>
	  </reference>
	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/querymesh.txt" 
	             anchor="refs.QueryMesh">
	    <front>
		  <title>
		    Query Mesh v0.1
		  </title>
		  <author initials="V.F." surname="Falco" fullname="Vincent Falco">
			<organization>
			  Free Peers, Inc.
			</organization>
			<address>
			  <uri>http://www.freepeers.com</uri>
			</address>
		  </author>
		  <author initials="S.D." surname="Darwin" fullname="Sam Darwin">
			<organization>
			  Free Peers, Inc.
			</organization>
			<address>
			  <uri>http://www.freepeers.com</uri>
			</address>
		  </author>
		  <date month="March" year="2002"/>
		</front>
	  </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/message/9533"
	             anchor="refs.http_mesh_proxy">
        <front>
          <title>Gnutella over HTTP, Query Mesh, Push Proxy</title>
          <author initials="T.K." surname="Klingberg"
                  fullname="Tor Klingberg">
		    <address>
			  <uri>http://www.freepeers.com</uri>
			</address>
          </author>
          <date month="August" year="2002" />
        </front>
      </reference>

      <?rfc include="reference.RFC.2119" ?>

      <reference target="http://groups.yahoo.com/group/the_gdf/message/4492"
	             anchor="refs.agthorr">
	    <front>
	      <title>Re: GGEP 0.31 comments
		  </title>
		  <author initials="D.S." surname="Agthorr" fullname="Agthorr">
		    <organization>
			  Gnutella Developer Forum
			</organization>
			<address>
			</address>
		  </author>
		  <date month="January" year="2002"/>
		</front>
	  </reference>
	  <reference target="http://www.amazon.com/exec/obidos/tg/detail/-/0201633469/qid=1029899071/sr=8-1/ref=sr_8_1/002-2563381-7557664?s=books&n=507846"
	             anchor="refs.TCPIP">
	    <front>
		  <title>The Protocols (TCP/IP Illustrated, Volume 1)</title>
		  <author initials="R.S." surname="Stevens" fullname="W. Richard Stevens">
		  </author>
		  <date month="January" year="1994"/>
		</front>
	  </reference>

      <?rfc include="reference.RFC.1191" ?>

	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/GGEP/GnutellaGenericExtensionProtocol.0.51.html"
	             anchor="refs.GGEP">
        <front>
          <title>Gnutella Generic Extension Protocol (GGEP) v0.51</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="Fedruary" year="2002" />
        </front>
      </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/Download%20Proxy/Download%20Proxy.html"
	             anchor="refs.download_proxy">
        <front>
          <title>Download Proxy v0.1</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="January" year="2002" />
        </front>
      </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/message/9317"
	             anchor="refs.push_proxy">
        <front>
          <title>Push Proxy v0.1</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="August" year="2002" />
        </front>
      </reference>

      <reference anchor="refs.clip2"
                 target="http://www.clip2.com/GnutellaProtocol04.pdf">
        <front>
          <title>The Gnutella Protocol Specification v0.4, Document Revision 1.2</title>
          <author fullname="Clip2">
            <organization>Clip2</organization>
          </author>
          <date month="" year="" />
          <note title="URL"><t>http://www.clip2.com/GnutellaProtocol04.pdf</t></note>
          <note title="URN"><t>urn:sha1:PLSTHIPQGSSZTS5FJUPAKUZWUGYQYPFB</t></note>
        </front>
      </reference>
	</references>

	<section title="Acknowledgements">
	  <t>
	    The authors would like to thank Christopher Rohrs and the rest of the 
		LimeWire team.  In addition, we would like to thank Gordon Mohr of Bitzi,
		Inc., Jakob Eriksson, Ph.D. student at the Computer Science department at
		the University of California, Riverside, all participants in the 
		Gnutella Developer Forum (GDF), and all members of the LimeWire open 
		source initiative.
	  </t>
	</section>
  </back>
  
</rfc>