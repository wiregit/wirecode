<?xml version="1.0"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc private="Gnutella Developer Forum"?>
<?rfc header="The GDF"?>
<?rfc compact="yes"?>
<?rfc toc="yes"?>
<rfc docname="gnutella-unicast-search-01">
  <front>
    <title>
	  Gnutella UltraPeer Walking v0.01
	</title>
    <author initials="S.D" surname="Daswani" fullname="Susheel Daswani">
	  <organization>LimeWire LLC</organization>
	  <address>
	    <email>sdaswani@limewire.com</email>
	    <uri>http://www.limewire.org</uri>
      </address>
	</author>
    <author initials="A.F" surname="Fisk" fullname="Adam A. Fisk">
	  <organization>LimeWire LLC</organization>
	  <address>
	    <email>afisk@limewire.com</email>
	    <uri>http://www.limewire.org</uri>
      </address>
	</author>
    <date month="August" year="2002"/>
    <area>applications</area>
	<keyword>Gnutella</keyword>
	<keyword>UDP</keyword>	
	<keyword>unicast</keyword>	
	<keyword>search</keyword>	
	<keyword>GDF</keyword>	
	<keyword>Gnutella Developer Forum</keyword>	
	<keyword>LimeWire</keyword>	
    <abstract>
	  <t>
	    This RFC outlines a technique for performing unicast searches 
		of UltraPeers on the Gnutella network.  Shifting from the 
		current broadcast search model to this system of unicast 
		searches can dramatically reduce the overall network bandwidth, 
		CPU, and memory required to support the Gnutella search 
		architecture while providing search results comparable to 
		the old broadcast model.  For rare files, the unicast search 
		model may even provide better results than broadcast.
	  </t>
    </abstract>
  </front>

  <middle>
    <section anchor="intro" title="Introduction">
	  <section title="Purpose">
	  <t>
        The use of broadcast searches with high Time To Live (TTL)s on the 
	    Gnutella network uses a great deal of bandwidth and provides little 
	    control over the propagation of 
		messages.<xref target="refs.RandomWalk"/>  This document seeks to 
	    alleviate both problems through the use of iterative unicast 
	    searches of Gnutella UltraPeers.<xref target="refs.UltraPeer"/>
	    In this scheme, a client continuously queries UltraPeers with a TTL 
	    of 1 until the desired number of search results is achieved.  Due 
	    to the number of nodes that may be dynamically queried in this model,
	    these messages are sent over UDP in the absence of static TCP 
	    connections.  This proposal is not intended to replace work 
		done in areas such as query 
		meshes.  (See <xref target="refs.QueryMesh"/> and <xref target="refs.http_mesh_proxy"/>)
		It does not, for example, easily allow existing web servers to 
		be modified to service queries.  Rather, it combines aspects of 
		several powerful ideas from different parties, most notably the 
		importance of carefully controlling query propagation and the 
		potential for queries and replies to be sent over UDP, making 
		such a system feasible.
	  </t>
	  </section>
	  <section anchor="requirements" title="Requirements">
        <t>The key words “MUST”, “MUST NOT”, “REQUIRED”, 
		“SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, 
		“RECOMMENDED”, “MAY”, and “OPTIONAL” in this 
		document are to be interpreted as described in 
		RFC 2119.<xref target="refs.RFC2119"/>
		An implementation is not compliant if it fails to satisfy one or 
		more of the MUST or REQUIRED level requirements for the protocols 
		it implements. An implementation that satisfies all the MUST or 
		REQUIRED level and all the SHOULD level requirements for its 
		protocols is said to be “unconditionally compliant”; one that 
		satisfies all the MUST level requirements but not all the SHOULD 
		level requirements for its protocols is said to be “conditionally
        compliant.”</t>
	  </section>
	  <section anchor="problems" title="Problems with the Current Model">
	    <t>The current broadcast search model consumes excessive bandwidth 
	    and produces a high load on nodes.  This occurs because: 

	      <list style="bullets">
	        <t>The number of nodes queried per search is uncontrolled.</t>
	        <t>Even if the number of nodes queried per search were constant,
		    the number of query hits generated per search would still be 
		    highly variable.</t>
	      </list>
        </t>
		  
        <section anchor="queries" title="Out of Control Queries">
	      <t>The first problem is a result of the volatile, ad-hoc nature of
		  Gnutella.  Nodes come and go unpredictably, making the connectivity
		  of different parts of the network highly variable, or at least
		  potentially so.  The current query model accounts for this
		  volatility by flooding -- it always takes whatever it can.
		  It does this by:

	        <list style="bullets">
		      <t>Sending queries with high TTLs (typically 7), making the 
		      number of nodes searched unpredictable and dependent upon the 
		      network topology.</t>
		      <t>Always forwarding queries to all connected nodes (it floods 
		      whenever the TTL is above 1) regardless of variable conditions.</t>
	        </list>

	      As a result, searches for common keywords in highly 
		  connected areas of the network have disproportionate impacts 
		  on network load, while searches for less common keywords in
		  less connected areas are not able to reach enough nodes to
		  obtain a satisfactory number of replies.
		  </t> 
		</section>

		<section anchor="hits" title="Out of Control Query Hits">
		  <t>While the unpredictable nature of queries presents the first half 
		  of the problem, the unpredictable nature of query hits has a comparable 
		  debilitating effect.  The problem with queries spills over into 
		  hits -- a variable number of nodes queried results 
		  in a variable number of query hits.  The problem is more serious 
		  than this, however.  The number of query hits generated per 
		  search also varies independently because:
	  
	        <list style="bullets">
	          <t>Some searches match a far higher percentage of files than other
		      searches (a search for "txt" produces more results than a search
		      for "The_Gettysburg_Address.txt").</t>
	          <t>Some nodes share more files than others, so the query hits 
		      depend not only on the number of nodes queried, but on which
		      nodes queries happen to reach.</t>
	        </list>

		  With this system, users frequently get more results than they need 
		  for popular content while they have a difficult time finding files
		  that are not as widely distributed.  In either case, queries and query 
		  hits follow the same model where they are allowed to run wild,
		  devouring network resources as they go.
	      </t>
	    </section>
	  </section>
	  <section title="Switch to Iterative Unicast">
	    <t>
	      We propose to alleviate these issues by reducing the TTL to 1 on
		  outgoing queries and by sending queries to one UltraPeer at a time
		  until some desired number of results is received or a limit on
		  the number of UltraPeers queried is reached.  Such a change 
		  grants the client initiating a query substantially more control
		  over the number of nodes the query reaches and over the number of 
		  query hits generated.  As such, it takes a significant step
		  towards solving the primary two problems with the current query
		  model noted above.  It does not eliminate these issues because
		  UltraPeers have varying numbers of leaves, nodes still share
		  varying numbers of files, and some searches will still return
		  far more results from given UltraPeers than others.
		  Nevertheless, this change dramatically mitigates the effects
		  of these problems.
	    </t>
	  </section>
	</section>
	<section anchor="searching_architecture" title="Searching Architecture">
	  <t>
	    In several ways, this scheme is simple and easy to 
		implement.  In particular, the system is completely transparent
		to leaves.  From the leaf perspective, the search system has
		not changed at all.  From the UltraPeer perspective, it is simply 
		a switch to sending out all queries with TTL=1 while querying
		a much larger set of UltaPeers directly over UDP, in addition
		to the traditional queries on intra-UltraPeer connections over
		TCP.


		<vspace/>
		<vspace/>
		The details of the UltraPeer changes are significant.  UltraPeers 
		must send queries iteratively to known UltraPeers via UDP,
		stopping when enough results are received.  UltraPeers are 
		also responsible for maintaining a full cache of other 
		UltraPeers that they can query via UDP.
		The following sections discuss these changes.		
	  </t> 
	  <section anchor="algorithm" title="Basic Algorithm">
	    <t>
		UltraPeers query other UltraPeers one by one until they receive
		a desired number of results or queries are sent to a maximum 
		number of UltraPeers.  When performing this 
		search, UltraPeers MUST NOT query the same UltraPeer more than
		once, as doing so would defeat the purpose of the proposal.
		If a client does not receive any results from a given 
		UltraPeer, it MUST assume the UltraPeer has no results
		to return, and not that the datagram was lost.  This is 
		necessary because the datagram being lost would indicate 
		congestion around that UltraPeer, and resending queries to
		that UltraPeer would lead to yet higher congestion.  
		Clients also MUST pause for a reasonable amount of time 
		between queries to UltraPeers, perhaps about 600 milliseconds.
		The ideal interval between queries should be determined by 
		experimentation, but clients SHOULD send as few queries as 
		possible without degrading user experience.  The client MUST 
		stop querying when it either receives "enough" replies or it 
		has queried a maximum number of UltraPeers.  A simple 
		algorithm would be for the client to continue querying until
		it has received 100 results or queried 1,000 UltraPeers,
		for example.  An alternative would be for the number of 
		results considered "enough" to decrease as a function
		of the number of UltraPeers searched.  This algorithm would 
		recognize, for example, that if a search has returned no
		results after querying 500 UlraPeers, it is unlikely
		to get very many results from querying the next 500,
		and it may be satisfied as soon as it receives any results
		at all and stop there.  This would reduce the total number
		of UltraPeers required to service queries for rare files.
		The details of these algorithms should also be determined 
		through experimentation by client developers, again keeping
		in mind that the overall 
		goal is to reduce query and query hit traffic for 
		everyone while maintaining searchability and improving
		searchability for rare files.  In any case, a client 
		MUST NOT query more than 10,000 UltraPeers for a given 
		search.  Similarly, clients MUST NOT require more than
		3,000 results prior to terminating the search.
		</t>
	  </section>
	  <section anchor="discovery" title="UltraPeer Discovery">
	    <t>
		  For this scheme to work, all UltraPeers must have the
		  ability to discover other UltaPeers.  UltraPeers 
		  supporting this proposal MUST advertise this fact
		  using a <xref target="ggep_pongs">GGEP extension</xref> 
		  in pongs.  UltraPeers also MUST ensure that they always
		  have a full cache of other UltraPeers to query.  
		  Because leaves always query the network via their
		  UltaPeer, leaves do not have to maintain a set of
		  UltraPeers to query, as this is the UltraPeer's 
		  responsibility.		  
		  <vspace/>
		  <vspace/>
		  If an UltaPeer's cache of other UltraPeers drops
		  below a certain threshold, for example 1000, the
		  UltraPeer MUST take steps to refresh its cache.  
		  It does so using the normal broadcast ping message, 
		  looking for 
		  the <xref target="ggep_pongs">GGEP extension</xref> in
		  pongs.  UltraPeers also SHOULD read any pongs that
		  they pass, even when not intended for them directly,
		  to limit the need to send broadcast
		  pings on their own.
		</t>
	  </section>
	  </section>
	<!--
	<section anchor="searching_architecture" title="Searching Architecture">
	  <t>
	    The basic architecture of this search system is simple.  Client
		nodes query UltraPeers one by one until they receive
		a desired number of results or queries are sent to a maximum 
		number of UltraPeers.  
		Clients <xref target="discovery">discover</xref> unicast-enabled
		UltraPeers through a <xref target="ggep_pongs">GGEP
		extension</xref> in pongs.  This is discussed in another 
		<xref target="discovery">section</xref>.  When performing this 
		search, clients MUST NOT query the same UltraPeer more than
		once, as doing so would defeat the purpose of the proposal.
		If a client does not receive any results from a given 
		UltraPeer, it MUST be assumed the UltraPeer has no results
		to return, and not that the datagram was lost.  This is 
		necessary because the datagram being lost would indicate 
		congestion around that UltraPeer, and resending queries to
		that UltraPeer would lead to yet higher congestion.  
		Clients also MUST pause for a reasonable amount of time 
		between queries to UltraPeers, perhaps about 600 milliseconds.
		The ideal interval between queries should be determined by 
		experimentation, but clients SHOULD send as few queries as 
		possible without degrading user experience.  The client MUST 
		stop querying when it either receives "enough" replies or it 
		has queried a maximum number of UltraPeers.  A simple 
		algorithm would be for the client to continue querying until
		it has received 100 results or queried 1,000 UltraPeers,
		for example.  An alternative would be for the number of 
		results considered "enough" to decrease as a function
		of the number of UltraPeers searched.  This algorithm would 
		recognize, for example, that if a search has returned no
		results after querying 500 UlraPeers, it is unlikely
		to get very many results from querying the next 500,
		and it may be satisfied as soon as it receives any results
		at all and stop there.  This would reduce the total number
		of UltraPeers required to service queries for rare files.
		The details of these algorithms should also be determined 
		through experimentation by client developers, again keeping
		in mind that the overall 
		goal is to reduce query and query hit traffic for 
		everyone while maintaining searchability and improving
		searchability for rare files.  In any case, a client 
		MUST NOT query more than 10,000 UltraPeers for a given 
		query.   
		<vspace/>
		<vspace/>
		Firewalls and security complicate the system.  The
		following sections discuss the searching 
		algorithm in detail from both the client and the server 
		perspective.  For each, both the firewalled and the 
		non-firewalled cases are addressed.  In this discussion, 
		the "server" is the node responding to a query, whereas
		the "client" is the node initiating the query.  In all
		discussions of firewalled nodes (on both the server side and
		the client side), the firewalled nodes are presumed to 
		be leaves.

		From the perspective of nodes initiating queries and
		nodes responding to queries, In this discussion, 
		the "server" is the node responding to a query, whereas
		the "client" is the node initiating the query.  In all
	  </t>
	</section>
	  <section anchor="client" title="Searching on the Client Side">
	    <section anchor="client_not_firewalled" title="Client Not Firewalled">>
	      <t>
		    When the client is not firewalled, that client sends 
		    queries via <xref target="udp">UDP datagrams</xref> 
		    directly to UltraPeers supporting
		    unicast queries.  The non-firewalled client bypasses 
		    its own UltraPeers completely (the ones connected via TCP),
		    although it MAY send TTL=1 queries to them as well over
		    the normal TCP connection.  Such a querying client must include
		    the <xref target="ggep_ip_port">GGEP extension</xref> in
		    queries advertising the IP and UDP port that results should
		    be returned to.		  
		  </t>
	    </section>
	    <section anchor="client_firewalled" title="Client Firewalled">
	      <t>
			  If the client is firewalled, it must use one
			  of its UltraPeers to proxy its query.  This is the case
			  because servers cannot send replies over incoming
			  UDP datagrams.  While firewalled clients could send outgoing
			  queries over UDP, doing so would create 
			  <xref target="security">security</xref> problems.  Therefore,
			  a firewalled client must send a query to one of its
			  UltraPeers that has the ability to serve as a search proxy.
			  The query MUST have yet another GGEP extension that 
			  specifies that the UltraPeer should handle the query on
			  the leaf's behalf.  This extension is described in the
			  <xref target="ggep">section</xref> on GGEP extensions.
			  <vspace/>
			  <vspace/>
			  When the UltraPeer receives such a marked query from one
			  of its leaves, it conducts the
			  search precisely as if it were searching on its own,
			  except that it routes all replies back to the leaf that
			  initiated the query.  While this increases the load on
			  UltraPeers, it allows firewalled leaves to use this
			  search model without exposing the network to attack.
			  <vspace/>
			  <vspace/>
			  This algorithm applies regardless of the firewalled status
			  of any receiving clients.		  
		  </t>
	    </section>
	  </section>
	  <section anchor="server" title="Responding to Searches on the Server Side">
	    <section anchor="server_not_firewalled" title="Server Not Firewalled">
		  <t>
			  When the server is not firewalled and it
			  has matching query hits, it MUST reply via UDP to the IP and 
			  UDP port advertised in the 
			  query's <xref target="ggep_ip_port">GGEP extension</xref>.  The
			  only exception is when the server is an UltraPeer.
			  In this case, the UltraPeer should drop the query entirely
			  if the advertised IP address does not match the IP address
			  of the datagram itself.  This issue is discussed further in
			  the section 
			  on <xref target="security">security considerations</xref>.	
		  </t>	  
		</section>
		<section anchor="server_firewalled" title="Server Firewalled">
		    <t>
			  When the server is firewalled, it sends its reply back
			  the UltraPeer that sent it the query, ignoring any IP and 
			  port listed for UDP responses in the 
			  query's <xref target="ggep_ip_port">GGEP extension</xref>.
			  So, in the firewalled case, servers (leaves in this case) 
			  handle the query precisely as they do in the traditional
			  Gnutella scheme.
			  <vspace/>
			  <vspace/>
			  At first, this choice may seem strange, as the firewalled
			  server could send an outgoing datagram directly to the
			  client.  It uses the UltraPeer because hosts must use a 
			  PUSH request when requesting its files, and the UltraPeer 
			  must have its client GUID in its push routing tables in order 
			  to service such a request.  If this were not the case, it 
			  would be able respond directly to the IP and UPD port 
			  listed in the query.  Responding through the UltraPeer
			  allows the use of the existing push 
			  architecture.(See <xref target="push"/>)
			</t>
		</section>
	  </section>
	  
    <section anchor="other_cases" title="Other Cases">
	  <section anchor="both_firewalled"
		       title="Both Client and Server are Firewalled">
	    <t>
	      In the case that both the client and the server
		  are firewalled, the client simply follows the rules for 
		  firewalled clients, and the server simply follows the 
		  rules for firewalled servers.
	    </t>
	  </section>
	  <section anchor="legacy" 
	           title="Searching Leaves that do Not Implement UGS">
        <t>
		  When an UltraPeer receives an incoming UPD query, it MUST
		  forward that query to all appropriate leaves whether or not
		  those leaves implement this proposal.  Older leaves will, of
		  course, be unable to return results via UDP.  In fact, they
		  will respond to the query just as they would any other query,
		  gracefully ignoring the additional GGEP block.  The UltraPeer,
		  however, has the additional responsibility of routing any of
		  these query hits back to the sender via UDP.  This should 
		  occur naturally depending on the implementation.  These
		  leaves are handled in the exact same way as firewalled
		  leaves that do implement this 
		  proposal.  (See <xref target="server_firewalled"/>)
		</t>
      </section>
	</section>
	-->

      <section anchor="udp" title="UDP">
	    <t>
	      In this scheme, clients must dynamically query a 
	      potentially high number of UltraPeers directly for each 
		  search.  In the current Gnutella network, all messages are
		  sent using TCP, so the most obvious implementation of this
		  proposal would use a new, transient connection also over TCP.  
		  Opening and closing TCP connections incurs significant CPU 
		  and memory costs, however, potentially making the proposed
		  change unworkable.  As others have noted, however, the 
		  reliability of TCP is not a requirement for Gnutella 
		  queries and replies.  If a message is lost, who cares?  
		  In fact, these queries and their associated replies can 
		  easily be sent over UDP.  In many ways, UDP is the more 
		  appropriate transport layer protocol -- we're sending messages 
		  to an amorphous group of nodes, and reliability is not 
		  a requirement.  Clients wishing to implement this change
		  MUST do so over UDP, as a TCP implementation would incur
		  excessive overhead for other nodes, and would be 
		  impossible without a new, transient connection.
	    </t>
		<section anchor="port" title="Open a UDP Port">
		  <t>
		    To implement this change, clients MUST open a UDP
			port that listens for incoming UDP traffic.  It is
			RECOMMENDED that clients listen on port 6346, the same
			port registered for Gnutella for TCP.
			Clients MAY, however, listen 
			on a different port, particularly when, for example,
			there is anothing Gnutella client listening on 6346,
			or when another application is using that port for
			any reason.  In all cases, however, clients MUST
			listen on the same port for both TCP and UDP traffic.
			This makes the implementation slightly more
			rigid.  The IP and TCP port are already reported in a
			number of Gnutella messages, headers, and extensions, 
			however, and this choice makes the reuse of that 
			information possible.  One example is the "Listen IP" 
			connection handshaking header that we will use right
			away to check the firewalled status of leaves.
		  </t>
		</section>
		<section anchor="fragmentation" title="Fragmentation">
		  <t>
		    One difference between UDP and TCP is that UDP does 
			not perform any segmenting of datagrams on its own:
			it sends a single datagram that may be split into
			multiple packets at the IP layer, either at the 
			originating host or at an intermediate router.  
			This fragmentation depends upon the 
			Maximum Transmission Unit (MTU) of the underlying
			link-layer.<xref target="refs.TCPIP"/>  
			<vspace/>
			<vspace/>
			Fragmentation of datagrams in itself is far from
			disastrous.  The IP layer reassembles packets into 
			complete datagrams at the destination host, making
			the process largely transparent to application 
			developers.  The danger lies, however, in the 
			possibility that individual packets are lost.  If 
			any fragment is lost, the entire datagram 
			is lost.<xref target="refs.TCPIP"/>  It is
			therefore RECOMMENDED that clients take steps
			to minimize the size of their datagrams to avoid
			excessive fragmentation.  The MTU of modem links
			can be prohibitively small, as low as 296 bytes,
			so we make no attempt to remain below this 
			threshold.<xref target="refs.MTU"/>  These links
			should only occur on the edges of the network,
			however, as long as UltraPeer election algorithms are 
			correctly measuring bandwidth.  This means that any
			fragmentation that may occur along modem links will
			likely result in little to no packet loss, so we
			need not consider this barrier when determing
			datagram sizes.  In general, clients SHOULD limit the
			size of their datagrams whenever appropriate.  A limit
			of 512 is very conservative, and limiting datagrams 
			to 1,024 bytes or less should avoid fragmentation on
			the vast majority of routers.  This will often not
			be possible for query hits.  Hits returning many
			results, however, may indicate an overly general 
			query (such as "txt"), so client MAY choose to
			limit the responses per query hit to limit the 
			overall size.
		  </t>
		</section>
		<section anchor="congestion" title="Congestion">
		  <t>
		    Another significant difference between TCP and UDP
			is that UDP does not provide congestion control.
			Given that this query scheme dramatically reduces
			overall message traffic, congestion may not be a 
			concern.  If congestion does prove to cause a 
			high degree of packet loss, however, clients
			may be forced to implement congestion control
			at the application layer.  The architecture for
			such a scheme is beyond the scope of this
			proposal.
		  </t>
		</section>
	  </section>

	    <section anchor="security" title="Security Considerations">
		  <section title="Distributed Denial of Service (DDOS) Attack">
		  <t>
			In the past, a principal objection to using UDP has been
			that it allows anyone to easily execute a DDOS attack
			on any target machine.  To execute such an attack, a
			node would simply have to send out queries advertising 
			the IP and port of the target machine in the GGEP block.
			If no precautions were taken, all replying nodes would
			attempt to reply to the target machine, quickly flooding
			it with UDP datagrams.  			  
	      </t>
		  </section>
		  <section title="DDOS Prevention">
		    <t>
			  To prevent such an attack, UltraPeers MUST verify that
		      the IP address in the advertised GGEP block matches the 
		      source IP address of the datagram itself.
		      The ports are allowed to vary, as clients
			  MAY send their UDP queries out over ephemeral ports.
			  Clients also MAY send these queries over TCP while 
			  expecting replies over UDP.  If the advertised IP 
			  address does not match the IP address of the datagram, 
			  UltraPeers MUST discard the query.  By performing this 
			  check, UltraPeers largely thwart the attack described 
			  above.  With this check in place, attackers would have 
			  to establish UltraPeers themselves on a large scale and let 
			  these queries through, which is difficult.  This security 
			  check is required because not performing this check would 
			  effectively do the attackers' work for them.
			</t>
		  </section>
		</section>
	<section anchor="other" title="Other Considerations">
	  <section anchor="push" title="Push Downloads">
	    <t>
		  This query scheme gracefully handles push downloads.  In
		  fact, it incorporates many of the ideas of the 
		  Push Proxy proposal.<xref target="refs.push_proxy"/>
		  This scheme does not, however, allow two firewalled hosts
		  to download from each other, as in the "Download Proxy"
		  proposal.<xref target="refs.download_proxy"/>
		</t>
	  </section>
	</section>
		  <section anchor="ggep" title="GGEP Extensions">
			<section anchor="ggep_pongs" title="Advertise UDP port in Pongs">
			  <t>
			    UltraPeers that are capable of receiving Gnutella 
			    messages over UDP MUST advertise that fact in a
			    new GGEP extension in 
			    pongs.<xref target="refs.GGEP"/>  This extension simply
			    lists the UDP port that the UltraPeer is listening on,
			    notifying other nodes of its presense.
			    TODO: describe the GGEP extension in more detail.		  
		      </t>
		    </section>
		  </section>
    <section anchor="features" title="Additional Features">
	  <section anchor="cycles" title="Cycles No Longer a Concern">
	    <t>
	      Adoption of this proposal has several additional benefits.  For example,
		  concern for cycles in intra-UltraPeer connections is eliminated.  In the
		  current network, cycles can be a serious problem in the worst case,
		  resulting in nodes receiving many duplicate 
		  messages.<xref target="refs.RandomWalk"/>  This eliminates
		  these duplicates except in the case where leaves are connected to 
		  multiple UltraPeers, and two or more of their UltraPeers are sent
		  the same query.
	    </t>
	  </section>
	</section>
  </middle>
  <back>
    <references>
	  <reference target="http://www.cs.princeton.edu/~qlv/download/searchp2p_full.pdf" 
	             anchor="refs.RandomWalk">
	    <front>
		  <title>
		    Search and Replication in Unstructured Peer-to-Peer Networks
		  </title>
		  <author initials="Q.V." surname="Lv" fullname="Qin Lv">
		    <organization>
			  Department of Computer Science, Princeton University
			</organization>
			<address>
			  <email>
			    qlv@cs.princeton.edu
			  </email>
			</address>
		  </author>

		  <author initials="P.C." surname="Cao" fullname="Pei Cao">
		    <organization>
			  Cisco Systems, Inc. 
			</organization>
			<address>
			  <email>
			    cao@cisco.com
			  </email>
			</address>
		  </author>

		  <author initials="E.C." surname="Cohen" fullname="Edith Cohen">
		    <organization>
			  AT&T Labs-Research
			</organization>
			<address>
			  <email>
			    edith@research.att.com
			  </email>
			</address>
		  </author>

		  <author initials="K.L." surname="Li" fullname="Kai Li">
		    <organization>
			  Department of Computer Science, Princeton University
			</organization>
			<address>
			  <email>
			    li@cs.princeton.edu
			  </email>
			</address>
		  </author>

		  <author initials="S.S." surname="Shenker" fullname="Scott Shenker">
		    <organization>
			  International Computer Science Institute (ICSI) 
			</organization>
			<address>
			  <email>
			    shenker@icsi.berkeley.edu
			  </email>
			</address>
		  </author>

		  <date month="June" year="2002"/>
		</front>
	  </reference>
	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/Ultrapeer/Ultrapeers_proper_format.html" 
	             anchor="refs.UltraPeer">
		<front>
	      <title>UltraPeers: Another Step Towards Gnutella Scalability</title>
		  <author initials="C.R." surname="Rohrs" fullname="Christopher Rohrs">
		    <organization>LimeWire LLC</organization>
			<address>
			  <uri>http://www.limewire.org</uri>
			</address>
		  </author>
		  <author initials="A.S." surname="Singla" fullname="Anurag Singla">
		    <organization>LimeWire LLC</organization>
			<address>
			  <uri>http://www.limewire.org</uri>
			</address>
		  </author>
		  <date month="December" year="2001"/>
		</front>
	  </reference>
	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/querymesh.txt" 
	             anchor="refs.QueryMesh">
	    <front>
		  <title>
		    Query Mesh v0.1
		  </title>
		  <author initials="V.F." surname="Falco" fullname="Vincent Falco">
			<organization>
			  Free Peers, Inc.
			</organization>
			<address>
			  <uri>http://www.freepeers.com</uri>
			</address>
		  </author>
		  <author initials="S.D." surname="Darwin" fullname="Sam Darwin">
			<organization>
			  Free Peers, Inc.
			</organization>
			<address>
			  <uri>http://www.freepeers.com</uri>
			</address>
		  </author>
		  <date month="March" year="2002"/>
		</front>
	  </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/message/9533"
	             anchor="refs.http_mesh_proxy">
        <front>
          <title>Gnutella over HTTP, Query Mesh, Push Proxy</title>
          <author initials="T.K." surname="Klingberg"
                  fullname="Tor Klingberg">
		    <address>
			  <uri>http://www.freepeers.com</uri>
			</address>
          </author>
          <date month="August" year="2002" />
        </front>
      </reference>

      <reference anchor="refs.RFC2119">
        <front>
          <title>Key words for use in RFCs to Indicate Requirement Levels</title>
          <author initials="S." surname="Bradner"
                  fullname="Scott Bradner">
            <organization abbrev="ISI">
              Harvard University
            </organization>
          </author>

          <date month="May" year="1997" />
        </front>
        <seriesInfo name="RFC" value="2119" />
      </reference>

      <reference target="http://groups.yahoo.com/group/the_gdf/message/4492"
	             anchor="refs.agthorr">
	    <front>
	      <title>Re: GGEP 0.31 comments
		  </title>
		  <author initials="D.S." surname="Agthorr" fullname="Agthorr">
		    <organization>
			  Gnutella Developer Forum
			</organization>
			<address>
			</address>
		  </author>
		  <date month="January" year="2002"/>
		</front>
	  </reference>
	  <reference target="http://www.amazon.com/exec/obidos/tg/detail/-/0201633469/qid=1029899071/sr=8-1/ref=sr_8_1/002-2563381-7557664?s=books&n=507846"
	             anchor="refs.TCPIP">
	    <front>
		  <title>The Protocols (TCP/IP Illustrated, Volume 1)</title>
		  <author initials="R.S." surname="Stevens" fullname="W. Richard Stevens">
		  </author>
		  <date month="January" year="1994"/>
		</front>
	  </reference>

	  <reference target="http://www.faqs.org/rfcs/rfc1191.html"
	             anchor="refs.MTU">
        <front>
          <title>Path MTU Discovery</title>
          <author initials="J.C." surname="Mogul"
                  fullname="J.C. Mogul">
          </author>
          <author initials="S.E." surname="Deering"
                  fullname="S.E. Deering">
          </author>
          <date month="November" year="1990" />
        </front>
        <seriesInfo name="RFC" value="1191" />
      </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/GGEP/GnutellaGenericExtensionProtocol.0.51.html"
	             anchor="refs.GGEP">
        <front>
          <title>Gnutella Generic Extension Protocol (GGEP) v0.51</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="Fedruary" year="2002" />
        </front>
      </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/Download%20Proxy/Download%20Proxy.html"
	             anchor="refs.download_proxy">
        <front>
          <title>Download Proxy v0.1</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="January" year="2002" />
        </front>
      </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/message/9317"
	             anchor="refs.push_proxy">
        <front>
          <title>Push Proxy v0.1</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="August" year="2002" />
        </front>
      </reference>
	</references>

	<section title="Acknowledgements">
	  <t>
	    The authors would like to thank the rest of the LimeWire team, all participants
		in the Gnutella Developer Forum (GDF), and all members of the LimeWire open
		source initiative.
	  </t>
	</section>
  </back>
  
</rfc>