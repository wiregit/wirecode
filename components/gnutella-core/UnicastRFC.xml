<?xml version="1.0"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc private="Gnutella Developer Forum"?>
<?rfc header="The GDF"?>
<?rfc compact="yes"?>
<?rfc toc="yes"?>
<rfc docname="gnutella-unicast-search-01">
  <front>
    <title abbrev="GUESS">
	  Gnutella Ultrapeer Extension for Scalable Searches (GUESS) v0.2
	</title>
    <author initials="S.D" surname="Daswani" fullname="Susheel Daswani">
	  <organization>LimeWire LLC</organization>
	  <address>
	    <email>sdaswani@limewire.com</email>
	    <uri>http://www.limewire.org</uri>
      </address>
	</author>
    <author initials="A.F" surname="Fisk" fullname="Adam A. Fisk">
	  <organization>LimeWire LLC</organization>
	  <address>
	    <email>afisk@limewire.com</email>
	    <uri>http://www.limewire.org</uri>
      </address>
	</author>
    <date month="August" year="2002"/>
    <area>applications</area>
	<keyword>Gnutella</keyword>
	<keyword>UDP</keyword>	
	<keyword>unicast</keyword>	
	<keyword>search</keyword>	
	<keyword>scalable</keyword>	
	<keyword>Gnutella scalability</keyword>	
	<keyword>GDF</keyword>	
	<keyword>walk</keyword>	
	<keyword>crawl</keyword>	
	<keyword>Gnutella Developer Forum</keyword>	
	<keyword>LimeWire</keyword>	
	<keyword>Susheel Daswani</keyword>	
	<keyword>Adam Fisk</keyword>	
    <abstract>
	  <t>
	    "GUESS" is a technique for performing iterative unicast 
		searches of Ultrapeers on the Gnutella network, or "Ultrapeer 
		crawling."  Shifting from the current broadcast search model 
		to this system can dramatically reduce the 
		overall network bandwidth, CPU, and memory required to support 
		the Gnutella search architecture while providing comparable 
		search results to the old broadcast model.  For rare files, the 
		unicast search model may even provide better results than 
		broadcast.
	  </t>
    </abstract>
  </front>

  <middle>
    <section anchor="intro" title="Introduction">
	  <section title="Purpose">
	  <t>
        The use of broadcast searches with high Time To Live (TTL)s on the 
	    Gnutella network uses a great deal of bandwidth and provides little 
	    control over the propagation of 
		messages.<xref target="refs.RandomWalk"/>  This document seeks to 
	    alleviate both problems through the use of iterative unicast 
	    searches of Gnutella Ultrapeers.<xref target="refs.Ultrapeer"/>
	    In this scheme, a client continuously queries Ultrapeers with a TTL 
	    of 1 until the desired number of search results is achieved.  Due 
	    to the number of nodes that may be dynamically queried in this model,
	    these messages are sent over UDP in the absence of static TCP 
	    connections.  This proposal is not intended to replace work 
		done in areas such as query 
		meshes.  (See <xref target="refs.QueryMesh"/> and <xref target="refs.http_mesh_proxy"/>)
		It does not, for example, easily allow existing web servers to 
		be modified to service queries.  Rather, it combines aspects of 
		several powerful ideas from different parties, most notably the 
		importance of carefully controlling query propagation and the 
		potential for queries and replies to be sent over UDP, making 
		such a system feasible.
	  </t>
	  </section>
	  <section anchor="requirements" title="Requirements">
        <t>The key words “MUST”, “MUST NOT”, “REQUIRED”, 
		“SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, 
		“RECOMMENDED”, “MAY”, and “OPTIONAL” in this 
		document are to be interpreted as described in 
		RFC 2119.<xref target="RFC2119"/>
		An implementation is not compliant if it fails to satisfy one or 
		more of the MUST or REQUIRED level requirements for the protocols 
		it implements. An implementation that satisfies all the MUST or 
		REQUIRED level and all the SHOULD level requirements for its 
		protocols is said to be “unconditionally compliant”; one that 
		satisfies all the MUST level requirements but not all the SHOULD 
		level requirements for its protocols is said to be “conditionally
        compliant.”</t>
	  </section>
	  <section anchor="problems" title="Problems with the Current Model">
	    <t>The current broadcast search model consumes excessive bandwidth 
	    and produces a high load on nodes.  This occurs because: 

	      <list style="bullets">
	        <t>The number of nodes queried per search is uncontrolled.</t>
	        <t>Even if the number of nodes queried per search were constant,
		    the number of query hits generated per search would still be 
		    highly variable.</t>
	      </list>
        </t>
		  
        <section anchor="queries" title="Out of Control Queries">
	      <t>The first problem is a result of the volatile, ad-hoc nature of
		  Gnutella.  Nodes come and go unpredictably, making the connectivity
		  of different parts of the network highly variable, or at least
		  potentially so.  The current query model accounts for this
		  volatility by flooding -- it always takes whatever it can.
		  It does this by:

	        <list style="bullets">
		      <t>
			    Sending queries with high TTLs (typically 7), making the 
		        number of nodes searched unpredictable and dependent upon the 
		        network topology.
			  </t>
		      <t>
			    Always forwarding queries to all connected nodes (it floods 
		        whenever the TTL is above 1) regardless of variable conditions.
			  </t>
	        </list>

	      As a result, searches for common keywords in highly 
		  connected areas of the network have disproportionate impacts 
		  on network load, while searches for less common keywords in
		  less connected areas are not able to reach enough nodes to
		  obtain a satisfactory number of replies.
		  </t> 
		</section>

		<section anchor="hits" title="Out of Control Query Hits">
		  <t>While the unpredictable nature of queries presents the first half 
		  of the problem, the unpredictable nature of query hits has a 
		  comparable debilitating effect.  The problem with queries spills 
		  over into hits -- a variable number of nodes queried results 
		  in a variable number of query hits.  The problem is more serious 
		  than this, however.  The number of query hits generated per 
		  search also varies independently because:
	  
	        <list style="bullets">
	          <t>Some searches match a far higher percentage of files than other
		      searches (a search for "txt" produces more results than a search
		      for "The_Gettysburg_Address.txt").</t>
	          <t>Some nodes share more files than others, so the query hits 
		      depend not only on the number of nodes queried, but on which
		      nodes queries happen to reach.</t>
	        </list>

		  With this system, users frequently get more results than they need 
		  for popular content while they have a difficult time finding files
		  that are not as widely distributed.  In either case, queries and query 
		  hits follow the same model where they are allowed to run wild,
		  devouring network resources as they go.
	      </t>
	    </section>
	  </section>
	  <section title="Switch to Iterative Unicast, or 'Ultrapeer Crawling'">
	    <t>
	      We propose to alleviate these issues by reducing the TTL to 1 on
		  outgoing queries and by sending queries to one Ultrapeer at a time
		  until some desired number of results is received or a limit on
		  the number of Ultrapeers queried is reached.  Such a change 
		  grants the client initiating a query substantially more control
		  over the number of nodes the query reaches and over the number of 
		  query hits generated.  As such, it takes a significant step
		  towards solving the primary two problems with the current query
		  model noted above.  It does not eliminate these issues because
		  Ultrapeers have varying numbers of leaves, nodes still share
		  varying numbers of files, and some searches will still return
		  far more results from given Ultrapeers than others.
		  Nevertheless, this change dramatically mitigates the effects
		  of these problems and makes the Gnutella network far more 
		  scalable.
	    </t>
	  </section>
	</section>
	<section anchor="searching_architecture" title="Searching Architecture">
	  <t>
	    In several ways, this scheme is simple and easy to 
		implement.  In particular, the system is completely transparent
		to leaves.  From the leaf perspective, the search system has
		not changed at all.  This simplifies the design and allows 
		any leaves not implementing this proposal to benefit from it
		nevertheless.  From the Ultrapeer perspective, implementing this
		proposal on a high level simply means sending out all 
		queries with TTL=1 while querying a much larger set of Ultrapeers 
		directly over either TCP or UDP.

		<vspace/>
		<vspace/>
		The details of the Ultrapeer changes are significant.  Ultrapeers 
		must send queries iteratively to known Ultrapeers supporting GUESS,
		stopping when enough results are received.  These queries can be
		sent via TCP if there is a TCP connection available.  Otherwise,
		they are sent over UDP.  Ultrapeers are also responsible
		for maintaining a full cache of other GUESS Ultrapeers to query.  
		On the server side, Ultrapeers must listen on a UDP port, and they 
		must send their responses over the same UDP port they are 
		listening on.  Aside from the protocol used when sending or 
		receiving messages, however, the changes are minimal.

		<vspace/>
		<vspace/>
		The following sections discuss the details of these changes.  In 
		this discussion, the "client" is the Ultrapeer initiating the 
		query, either on its own behalf or on behalf of one of its 
		leaves (most importantly, the "client" is never a leaf -- 
		it is always the Ultrapeer).  The "server" is the receiver 
		of the query, which can be either a leaf or an Ultrapeer.
		Developers implementing this proposal MUST implement both the 
		client side and the server side.  This means that any developers
		wishing to implement GUESS also MUST implement 
		the <xref target="refs.Ultrapeer">Ultrapeer proposal</xref>.				
	  </t> 
	  <section anchor="algorithm" title="Client">
	    <t>
		Ultrapeers send queries to other Ultrapeers one by one until 
		one of the following occurs:
		  <list style="numbers">
		    <t>
			  The desired number of results is received.
			</t>
			<t>
			  The maximum number of Ultrapeers is queried.
			</t>
		  </list>
		
		To make sure these queries do not flood the network with too
		much traffic, the client MUST pause for a reasonable amount
		of time between each query, perhaps about 200 milliseconds.  This 
		pause accounts for network latency, as it takes a variable 
		amount of time to receive results from an Ultrapeer
		and its leaves.  The interval allocates time to receive these
		replies.  During the interval, the desired number of results may
		be reached, making sending the query to another Ultrapeer 
		unnecessary.  The optimal 
		interval between searches should be determined by 
		experimentation, but implementors MUST send as few queries 
		as possible without degrading user experience and without 
		prohibitively increasing the load on participating 
		Ultrapeers. Implementations may also vary the interval 
		between queries depending on how many Ultrapeers 
		have already been reached.  For example, the interval may 
		be 400 milliseconds for the first 20 Ultrapeers, but then 
		go down to 200 for the next 100, potentially even getting
		smaller after that.  Such an algorithm may make sense 
		because the probability of receiving a reply to a given 
		query likely gets smaller as more Ultrapeers are queried
		and the desired number of results is not achieved.  At that
		point, it may make sense to speed up the query to quickly
		reach as many nodes as possible.  A simple algorithm would
		be to set the initial interval between queries to 1,500 
		milliseconds and multiply that interval by .75 on each 
		iteration.  In this scheme, the interval would eventually
		reach the minimum interval allowed and stay there.

		<vspace/>
		<vspace/>
		With regard to the desired number of results, 
		implementors have some flexibility, particularly in 
		their technique for determing what they consider "enough"
		results to stop the search.  A simple  
		algorithm would be for the client to continue 
		querying until it has received 100 results or queried 1,000 
		Ultrapeers, for example.  An alternative would be for the 
		number of results considered "enough" to decrease as a function
		of the number of Ultrapeers searched.  This algorithm would 
		recognize, for example, that if a search has returned no
		results after querying 500 UlraPeers, it is unlikely
		to get very many results from querying the next 500,
		and it may be satisfied as soon as it receives any results
		at all and stop there.  This would reduce the total number
		of Ultrapeers required to service queries for rare files.
		The details of these algorithms should also be determined 
		through experimentation by Gnutella developers, again keeping
		in mind that the overall goal is to reduce query and query 
		hit traffic for everyone while maintaining current levels of 
		searchability for common files and improving searchability 
		for rare files.  Clients should also keep in mind that an 
		overly aggressive implementation will ultimately damage 
		their own clients through increasing everyone's overall 
		network load.
		
		<vspace/>
		<vspace/>
		When performing this search, there are several rules that
		Ultrapeers MUST follow.  These are:
		  <list style="numbers">
		    <t>
			  Searches MUST NOT be sent to more than 10,000
			  Ultrapeers.
			</t>
			<t>
			  Clients MUST NOT seek more than 1,000 results.
			</t>
			<t>
			  Clients MUST NOT query more than 1 Ultrapeer every
			  20 milliseconds.  For the first 20 Ultrapeers
			  queried, however, clients MUST pause for at least 200 
			  milliseconds between queries.  The query should initially
			  begin slowly as it in effect determines the popularity
			  of the file.
			</t>
		    <t>
			  Ultrapeers MUST NOT query the same Ultrapeer more 
			  than once.  In particular, a node MUST NOT send a 
			  second query to an Ultrapeer if it does not receive responses 
			  to the first query (it MUST NOT consider that the datagram 
			  was lost and requery as a result).  If the datagram was,
			  in fact, lost, this indicates high loss around that node,
			  and resending the query will only make the situation worse.
			</t>
		  </list>

	    These numbers should be considered the absolute maximum
		values, and they are not the settings developers should use.
		Again, the optimal limits should be determined by 
		experimentation, but the above rules always apply.  Implementors
		should keep in mind that Gnutella is a network that relies on
		the fact that other clients are not overly selfish or
		abusive -- Gnutella relies on trust to a large degree.  
		The reduction in traffic should reduce the bandwidth, CPU, 
		and memory load on all Ultrapeers, but this is only possible 
		if developers use conservative values when writing their 
		implementations.
		</t>
	  </section>
	  <section anchor="server" title="Server">
	    <t>
	    The changes on the server side are less significant.  Again,
		no changes are required for leaves.  In fact, leaves SHOULD NOT 
		open UDP ports for incoming traffic, as they never receive UDP
		messages directly.  Ultrapeers MUST, however, open a port
		for incoming UDP traffic, and they MUST use the same 
		port that they are using for incoming Gnutella messages 
		over TCP.  The details of this are discussed in 
		the <xref target="udp">section</xref> on UDP.
		When a server receives a message over its open UDP
		port, it MUST send any replies via UDP and over the same
		port it is listening on.  As in the current Gnutella 
		network, all replies are sent back to the sender.  This is
		an important point in terms 
		of <xref target="security">security</xref>.  Otherwise,
		servers should respond to messages just as if they 
		recieved them over TCP.  Servers SHOULD accept all of the
		traditional Gnutella messages over their UDP port.  These
		messages are defined in 
		the <xref target="refs.clip2">Gnutella Protocol Specification v0.4</xref>.
		
		<vspace/>
		<vspace/>
		On the server side, Ultrapeers also MUST start forwarding 
		TTL=1 queries to leaves.  Without this change, queries would
		have to be sent with TTL=2, which would lessen the fine-grained
		control over the query and would eliminate benefits such as
		no longer needing to concern ourselves 
		with <xref target="cycles">cycles</xref>.  The current practice
		of not forwarding TTL=1 queries to leaves also fails to take
		advantage of the powerful Ultrapeer infrastructure that 
		can be used more productively. 
		</t>
	  </section>
	</section>
	<section anchor="discovery" title="Ultrapeer Discovery">
	    <t>
		  For this scheme to work, all Ultrapeers must have the
		  ability to discover other Ultrapeers that accept incoming
		  messages over UDP.  In fact, Ultrapeer discovery may be one
		  of the most challenging components of this proposal, as
		  Ultrapeers do not simply have to discover other Ultrapeers -- 
		  they have to discover LOTS of them.  As we will see, the 
		  scheme has Ultrapeer discovery built in to some degree. 
		  Ultrapeers supporting this proposal MUST advertise this fact
		  using a <xref target="ggep_pongs">GGEP extension</xref> in
		  pongs.  There are three techniques for discovering these
		  marked pongs on the network:
		    <list style="numbers">
			  <t>
			    Through standard Gnutella broadcast pings.
			  </t>			    
			  <t>
                Through specialized pings sent over UDP.
			  </t>
			  <t>
			    Through storing the IP and port of incoming UDP datagrams.
			  </t>
			</list>

		  The last technique is perhaps the most intriguing.  Each Ultrapeer
		  crawl may send out queries to 10,000 other nodes.  As a result,
		  Ultrapeers will naturally receive large numbers of queries over UDP
		  from other Ultrapeers that must be supporting this proposal.  They
		  can simply treat these queries as pongs, and add those Ultrapeers 
		  to their cache.  This is made possible because the host sending the
		  query has to be listening on the same port stored in the
		  datagram.  The same is true for any pings received over UDP.  
		  While these incoming messages will only supply the IP address and 
		  port of hosts supporting GUESS without the additional data 
		  contained in normal pongs, the IP address and port are really all 
		  that are necessary for our purposes.  This built-in distribution 
		  of host information can dramatically reduce the need for 
		  any pings and pongs at all -- so much so that Ultrapeers 
		  MUST store the IP and port from all UDP messages they receive.
		  Similarly, GUESS Ultrapeers MUST include these pongs when
		  appropriate in response to UDP pings.

		  <vspace/>
		  <vspace/>
		  The other specialized technique for Ultrapeer discovery is the
		  use of the normal Gnutella ping, only over UDP.  When Ultrapeers
		  receive pings over UDP, they should take special action.  Instead 
		  of returning the normal pongs, Ultrapeers are REQUIRED to send 
		  pongs from other Ultrapeers with 
		  the <xref target="ggep_pongs">GGEP extension</xref> marking 
		  support for GUESS.  They SHOULD send some moderate number of these
		  Ultrapeer pongs, somewhere in the range of about 5-20.  Given
		  that GUESS Ultrapeer discovery is one of the more difficult 
		  aspects of the proposal, the optimal number of pongs to send 
		  should be determined by experimentation.  Ultrapeers MUST NOT
		  include a pong for themselves in the returned set, as the
		  pinging Ultrapeer already knows about the Ultrapeers it pings.
		  This technique allows nodes to discover Ultrapeers outside the
		  network horizon of normal broadcast pings.

		  <vspace/>
		  <vspace/>
		  Using these techniques, Ultrapeers also MUST maintain
		  a full cache of other Ultrapeers to query.  
		  Because leaves always query the network via their
		  Ultrapeer, leaves do not have to maintain any of this 
		  information -- this is the Ultrapeer's 
		  responsibility.  If an Ultrapeer's cache of other GUESS-supporting 
		  Ultrapeers drops below a certain threshold, for example 5,000,
		  the Ultrapeer MUST refresh its Ultrapeer cache, most likely 
		  through sending pings over UDP.  While Ultrapeers MUST 
		  maintain an adequate cache of other Ultrapeers to query, 
		  they also MUST send a minimum number of pings to make 
		  this possible, less the network become flooded with ping 
		  and pong traffic.
		</t>
	</section>


      <section anchor="udp" title="UDP">
	    <t>
	      In this scheme, clients must dynamically query a 
	      potentially high number of Ultrapeers directly for each 
		  search.  In the current Gnutella network, all messages are
		  sent using TCP, so the most obvious implementation of this
		  proposal would use a new, transient connection also over TCP.  
		  Opening and closing TCP connections incurs significant CPU 
		  and memory costs, however, potentially making such a change
		  in architecture unworkable.  Moreover, Windows 95/98/Me do 
		  not allow more than 100 TCP connections.  While this 
		  setting can be changed in the registry, these systems 
		  were clearly not designed to handle high numbers of 
		  simultaneous connections.  As opposed to UDP, TCP also 
		  uses significantly more bandwidth and increases delay 
		  due to re-transmission.  As others have noted, however, 
		  the reliability of TCP is not a requirement for Gnutella 
		  messages.<xref target="refs.agthorr"/>  If 
		  a message is lost, who cares?  
		  In fact, these queries and their associated replies 
		  can easily be sent over UDP.  In many ways, UDP is the more 
		  appropriate transport layer protocol, as this scheme sends a 
		  large number of messages to an amorphous group of nodes
		  very quickly, making performance a concern while 
		  reliability is not a requirement.  In fact, 
		  with the high transience of Gnutella nodes, reliability cannot
		  be expected and is undesirable.  Clients wishing to implement 
		  this change MUST do so over UDP, as a TCP implementation would 
		  incur excessive overhead for other nodes, and would be 
		  impossible without a new, transient connection.  If a TCP
		  connection already exists, Ultrapeers MUST send messages
		  just as if the connection were over UDP, using TTL=1
		  in particular.
	    </t>
		<section anchor="port" title="Open a UDP Port">
		  <t>
		    To implement this change, Ultrapeers MUST open a UDP
			port that listens for incoming UDP traffic, as mentioned
			in the section on server-side changes.  It is
			RECOMMENDED that Ultrapeers listen on port 6346, the 
			same port registered for Gnutella for TCP.
			Ultrapeers MAY, however, listen 
			on a different port, particularly when, for example,
			there is another Gnutella client listening on 6346,
			or when another application is using that port for
			any reason.  In all cases, clients MUST
			listen on the same port for both TCP and UDP traffic.
			While this makes the implementation slightly more
			rigid, the IP and TCP port are already reported in a
			number of Gnutella messages, headers, and extensions, 
			however, and this choice makes the reuse of that 
			information possible.  
		  </t>
		</section>
		<section anchor="fragmentation" title="Fragmentation">
		  <t>
		    One difference between UDP and TCP is that UDP does 
			not perform any segmenting of datagrams on its own:
			it sends a single datagram that may be split into
			multiple packets at the IP layer, either at the 
			originating host or at an intermediate router.  
			This fragmentation depends upon the 
			Maximum Transmission Unit (MTU) of the underlying
			link-layer.<xref target="refs.TCPIP"/>  
			<vspace/>
			<vspace/>
			Fragmentation of datagrams in itself is far from
			disastrous.  The IP layer reassembles packets into 
			complete datagrams at the destination host, making
			the process largely transparent to application 
			developers.  The danger lies, however, in the 
			possibility that individual packets are lost.  If 
			any fragment is lost, the entire datagram 
			is lost.<xref target="refs.TCPIP"/>  It is
			therefore RECOMMENDED that clients take steps
			to minimize the size of their datagrams to avoid
			excessive fragmentation.  The MTU of modem links
			can be prohibitively small, as low as 296 bytes,
			so we make no attempt to remain below this 
			threshold.<xref target="RFC1191"/>  These links
			should only occur on the edges of the network,
			however, as long as Ultrapeer election algorithms are 
			correctly measuring bandwidth.  This means that any
			fragmentation that may occur along modem links will
			likely result in little to no packet loss, so we
			need not consider this barrier when determing
			datagram sizes.  In general, clients SHOULD limit the
			size of their datagrams whenever appropriate.  A limit
			of 512 is very conservative, and limiting datagrams 
			to 1,500 bytes or less should avoid fragmentation on
			the vast majority of 
			routers.<xref target="RFC1191"/>  This is because 
			1,500 bytes is the MTU for Ethernet links, which most
			TCP/IP stacks take into account.  Assuming 20 bytes 
			for the IP header and 8 bytes for the UDP header, this
			leaves 1,472 bytes for Gnutella message data.
			
			<vspace/>
			<vspace/>	
			It will often not be possible to keep query hits under
			the 1,472 byte limit.  To address this problem, 
			it is RECOMMENDED that developers break up large 
			query hits into multiple smaller 
			query hits.  This will increase the bandwidth required 
			to return results only slightly (due to sending the same 
			header multiple times) while reducing or eliminating fragmentation.
			It also avoids the current "all or nothing" approach where all 
			results from a host are lost if one packet is lost.  In this 
			scheme, some hits can still get through when a packet 
			from another hit is lost.
		  </t>
		</section>
		<section anchor="congestion" title="Congestion">
		  <t>
		    Another significant difference between TCP and UDP
			is that UDP does not provide congestion control.
			Given that this query scheme dramatically reduces
			overall message traffic, congestion may not be a 
			concern.  Particularly because clients will no longer receive
			the floods of query hits currently associated with 
			queries for popular content (probably the most severe 
			case of congestion on the current network), packet loss
			rates under this scheme should be significantly lower. 
			If congestion does prove to cause a 
			high degree of packet loss, however, clients
			may be forced to implement congestion control
			at the application layer.  The architecture for
			such a scheme is beyond the scope of this
			proposal and would require significant changes.
		  </t>
		</section>
	  </section>

	    <section anchor="security" title="Security Considerations">
		  <section title="Distributed Denial of Service (DDOS) Attack">
		  <t>
			In the past, a principal objection to using UDP has been
			that it allows anyone to easily execute a DDOS attack
			on any target machine.  This concern has been based on the
			assumption that queries would require an extension listing
			the IP address and UDP port to reply to, however.  In this
			proposal, this extension is not required, as responses are
			always sent directly back to the node that sent them, 
			rendering such an attack impossible.
	      </t>
		  </section>
		</section>
      <section anchor="ggep" title="GGEP Extensions">
	    <section anchor="ggep_pongs" title="Advertise GUESS Support in Pongs">
	      <t>
		    Ultrapeers that support GUESS MUST advertise that fact 
			in a new GGEP extension 
			in pongs.<xref target="refs.GGEP"/>  The GGEP 
			extension should have the value "GUE" as its
			extension header.
            The extension value will be 1 byte describing the protocol
			revision number.  The most-significant nibble will be an
			unsigned integer describing the major revision (the current
			major revision number is 0, hence 0000b).  The
			least-significant nibble will be the minor revision number
			(the current minor revision number is 2, hence 0010b).  Note
			that the nibbles represent the numbers with the
			most-significant bit first.  Moreover, this limits the
			revision numbers - 15 for major and minor revisions
			(therefore, there will never be a 1.16 or a 16.5 revision).
			This allows 256 possible unique revision numbers which should
			do for the life of the protocol.
		  </t>
		</section>
	  </section>
    <section anchor="features" title="Additional Features">
	  <section anchor="cycles" title="Cycles No Longer a Concern">
	    <t>
	      Adoption of this proposal has several additional benefits.  For 
		  example, concern for cycles in intra-Ultrapeer connections is 
		  eliminated.  In the current network, cycles can be a serious 
		  problem in the worst case.  As a general, the number of cycles 
		  increases as the connectivity of the network graph increases.
		  This is highly problematic because there are significant benefits
		  to having a more highly connected graph.  These cycles result in 
		  nodes receiving many duplicate messages, wasting bandwidth, CPU, and 
		  memory.(See <xref target="refs.RandomWalk"/> and <xref target="refs.tutorial"/>)  This 
		  eliminates these duplicates except in the case where leaves 
		  are connected to multiple Ultrapeers, and two or more of 
		  their Ultrapeers are sent the same query.
	    </t>
	  </section>
	  <section anchor="push" title="Higher Success Rate for Push Downloads">
	    <t>
		  This query scheme gracefully handles push downloads.  In
		  fact, it incorporates many of the ideas of the 
		  Push Proxy proposal.<xref target="refs.push_proxy"/>
		  This scheme does not, however, allow two firewalled hosts
		  to download from each other, as in the "Download Proxy"
		  proposal.<xref target="refs.download_proxy"/>  In the current
		  network, push requests frequently fail, primarily because
		  the node serving the file may be 7 Gnutella hops away from 
		  the node requesting a file, and the request has to travel through
		  all intervening nodes.  As a result, if any node along that
		  path leaves the network, the push will not go through.
		  With the adoption of this proposal, success rates for 
		  push request should increase dramatically, as the node 
		  serving the file will only be from 1 to 3 hops away (usually 
		  3 -- this depends on whether the searching and replying nodes
		  are leaves or Ultrapeers). 
		</t>
	  </section>
	  <section anchor="stop" title="Stopping Queries Has Meaning">
	    <t>
		  Another benefit of this scheme is that the user manually "stopping"
		  a query can, in fact, stop that query from being sent to more
		  hosts, saving network resources.
		</t>
	  </section>
	  <section anchor="improved_security" title="Moderately Improved Security">
	    <t>
		  GUESS has the added benefit that it makes the most obvious 
		  DDOS attack on Gnutella less feasible.  In such an attack, a
		  single attacker can connect to a large number of hosts simultaneously
		  and send out repeated queries for popular content with a high TTL.  
		  Given current flow control algorithms, relatively few attackers could
		  likely have a rapid and dramatic negative impact on overall network
		  performance.  While attackers can still connect to many Ultrapeers
		  in this scheme, the effective elimination of TTL in GUESS means that
		  an attacker would have to use far more bandwidth to achieve the
		  same effect.
		  <vspace/>
		  <vspace/>
		  In addition, GUESS makes Gnutella application-level 
		  "man in the middle" attacks more difficult.
		  With GUESS, there are fewer nodes between the sender and the
		  receiver, so each message will pass through far fewer nodes along
		  its path to the recipient.  So, while this by no means eliminates the 
		  ability to view and/or alter messages on the path to the recipient,
		  it makes it slightly more difficult.
		</t>
	  </section>
	</section>
  </middle>
  <back>
    <references>
	  <reference target="http://www.cs.princeton.edu/~qlv/download/searchp2p_full.pdf" 
	             anchor="refs.RandomWalk">
	    <front>
		  <title>
		    Search and Replication in Unstructured Peer-to-Peer Networks
		  </title>
		  <author initials="Q.V." surname="Lv" fullname="Qin Lv">
		    <organization>
			  Department of Computer Science, Princeton University
			</organization>
			<address>
			  <email>
			    qlv@cs.princeton.edu
			  </email>
			</address>
		  </author>

		  <author initials="P.C." surname="Cao" fullname="Pei Cao">
		    <organization>
			  Cisco Systems, Inc. 
			</organization>
			<address>
			  <email>
			    cao@cisco.com
			  </email>
			</address>
		  </author>

		  <author initials="E.C." surname="Cohen" fullname="Edith Cohen">
		    <organization>
			  AT&T Labs-Research
			</organization>
			<address>
			  <email>
			    edith@research.att.com
			  </email>
			</address>
		  </author>

		  <author initials="K.L." surname="Li" fullname="Kai Li">
		    <organization>
			  Department of Computer Science, Princeton University
			</organization>
			<address>
			  <email>
			    li@cs.princeton.edu
			  </email>
			</address>
		  </author>

		  <author initials="S.S." surname="Shenker" fullname="Scott Shenker">
		    <organization>
			  International Computer Science Institute (ICSI) 
			</organization>
			<address>
			  <email>
			    shenker@icsi.berkeley.edu
			  </email>
			</address>
		  </author>

		  <date month="June" year="2002"/>
		</front>
	  </reference>
	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/Ultrapeer/Ultrapeers_proper_format.html" 
	             anchor="refs.Ultrapeer">
		<front>
	      <title>Ultrapeers: Another Step Towards Gnutella Scalability</title>
		  <author initials="C.R." surname="Rohrs" fullname="Christopher Rohrs">
		    <organization>LimeWire LLC</organization>
			<address>
			  <uri>http://www.limewire.org</uri>
			</address>
		  </author>
		  <author initials="A.S." surname="Singla" fullname="Anurag Singla">
		    <organization>LimeWire LLC</organization>
			<address>
			  <uri>http://www.limewire.org</uri>
			</address>
		  </author>
		  <date month="December" year="2001"/>
		</front>
	  </reference>
	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/querymesh.txt" 
	             anchor="refs.QueryMesh">
	    <front>
		  <title>
		    Query Mesh v0.1
		  </title>
		  <author initials="V.F." surname="Falco" fullname="Vincent Falco">
			<organization>
			  Free Peers, Inc.
			</organization>
			<address>
			  <uri>http://www.freepeers.com</uri>
			</address>
		  </author>
		  <author initials="S.D." surname="Darwin" fullname="Sam Darwin">
			<organization>
			  Free Peers, Inc.
			</organization>
			<address>
			  <uri>http://www.freepeers.com</uri>
			</address>
		  </author>
		  <date month="March" year="2002"/>
		</front>
	  </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/message/9533"
	             anchor="refs.http_mesh_proxy">
        <front>
          <title>Gnutella over HTTP, Query Mesh, Push Proxy</title>
          <author initials="T.K." surname="Klingberg"
                  fullname="Tor Klingberg">
		    <address>
			  <uri>http://www.freepeers.com</uri>
			</address>
          </author>
          <date month="August" year="2002" />
        </front>
      </reference>

      <?rfc include="reference.RFC.2119" ?>

      <reference target="http://groups.yahoo.com/group/the_gdf/message/4492"
	             anchor="refs.agthorr">
	    <front>
	      <title>Re: GGEP 0.31 comments
		  </title>
		  <author initials="D.S." surname="Agthorr" fullname="Agthorr">
		    <organization>
			  Gnutella Developer Forum
			</organization>
			<address>
			</address>
		  </author>
		  <date month="January" year="2002"/>
		</front>
	  </reference>
	  <reference target="http://www.amazon.com/exec/obidos/tg/detail/-/0201633469/qid=1029899071/sr=8-1/ref=sr_8_1/002-2563381-7557664?s=books&n=507846"
	             anchor="refs.TCPIP">
	    <front>
		  <title>The Protocols (TCP/IP Illustrated, Volume 1)</title>
		  <author initials="R.S." surname="Stevens" fullname="W. Richard Stevens">
		  </author>
		  <date month="January" year="1994"/>
		</front>
	  </reference>

      <?rfc include="reference.RFC.1191" ?>

	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/GGEP/GnutellaGenericExtensionProtocol.0.51.html"
	             anchor="refs.GGEP">
        <front>
          <title>Gnutella Generic Extension Protocol (GGEP) v0.51</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="Fedruary" year="2002" />
        </front>
      </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/files/Proposals/Download%20Proxy/Download%20Proxy.html"
	             anchor="refs.download_proxy">
        <front>
          <title>Download Proxy v0.1</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="January" year="2002" />
        </front>
      </reference>

      <reference anchor="refs.tutorial"
                 target="http://www.ists.dartmouth.edu/IRIA/knowledge_base/p2p/p2p.pdf">
        <front>
          <title>File Sharing Protocols: A Tutorial on Gnutella</title>
          <author surname="Berk" fullname="Vincent Berk">
            <organization>Institute for Security Technology Studies</organization>
          </author>
          <author surname="Cybenko" fullname="George Cybenko">
            <organization>Institute for Security Technology Studies</organization>
          </author>
          <date month="March" year="2001" />
        </front>
      </reference>

	  <reference target="http://groups.yahoo.com/group/the_gdf/message/9317"
	             anchor="refs.push_proxy">
        <front>
          <title>Push Proxy v0.1</title>
          <author initials="J.T." surname="Thomas"
                  fullname="Jason Thomas">
		    <address>
			  <email>jason@jasonthomas.com</email>
			</address>
          </author>
          <date month="August" year="2002" />
        </front>
      </reference>

      <reference anchor="refs.clip2"
                 target="http://www.clip2.com/GnutellaProtocol04.pdf">
        <front>
          <title>The Gnutella Protocol Specification v0.4, Document Revision 1.2</title>
          <author fullname="Clip2">
            <organization>Clip2</organization>
          </author>
          <date month="" year="" />
          <note title="URL"><t>http://www.clip2.com/GnutellaProtocol04.pdf</t></note>
          <note title="URN"><t>urn:sha1:PLSTHIPQGSSZTS5FJUPAKUZWUGYQYPFB</t></note>
        </front>
      </reference>
	</references>

	<section title="Acknowledgements">
	  <t>
	    The authors would like to thank Christopher Rohrs and the rest of the 
		LimeWire team.  In addition, we would like to thank Gordon Mohr of Bitzi,
		Inc., Jakob Eriksson, Ph.D. student at the Computer Science department at
		the University of California, Riverside, all participants in the 
		Gnutella Developer Forum (GDF), and all members of the LimeWire open 
		source initiative.
	  </t>
	</section>
  </back>
  
</rfc>